{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Analysis Restaurant review data is Postive or Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Wow... Loved this place.\n",
       "1                                     Crust is not good.\n",
       "2              Not tasty and the texture was just nasty.\n",
       "3      Stopped by during the late May bank holiday of...\n",
       "4      The selection on the menu was great and so wer...\n",
       "5         Now I am getting angry and I want my damn pho.\n",
       "6                  Honeslty it didn't taste THAT fresh.)\n",
       "7      The potatoes were like rubber and you could te...\n",
       "8                              The fries were great too.\n",
       "9                                         A great touch.\n",
       "10                              Service was very prompt.\n",
       "11                                    Would not go back.\n",
       "12     The cashier had no care what so ever on what I...\n",
       "13     I tried the Cape Cod ravoli, chicken, with cra...\n",
       "14     I was disgusted because I was pretty sure that...\n",
       "15     I was shocked because no signs indicate cash o...\n",
       "16                                   Highly recommended.\n",
       "17                Waitress was a little slow in service.\n",
       "18     This place is not worth your time, let alone V...\n",
       "19                                  did not like at all.\n",
       "20                                   The Burrittos Blah!\n",
       "21                                    The food, amazing.\n",
       "22                                 Service is also cute.\n",
       "23     I could care less... The interior is just beau...\n",
       "24                                    So they performed.\n",
       "25     That's right....the red velvet cake.....ohhh t...\n",
       "26            - They never brought a salad we asked for.\n",
       "27     This hole in the wall has great Mexican street...\n",
       "28     Took an hour to get our food only 4 tables in ...\n",
       "29                     The worst was the salmon sashimi.\n",
       "                             ...                        \n",
       "970    I immediately said I wanted to talk to the man...\n",
       "971                      The ambiance isn't much better.\n",
       "972    Unfortunately, it only set us up for disapppoi...\n",
       "973                                The food wasn't good.\n",
       "974    Your servers suck, wait, correction, our serve...\n",
       "975        What happened next was pretty....off putting.\n",
       "976    too bad cause I know it's family owned, I real...\n",
       "977                 Overpriced for what you are getting.\n",
       "978                 I vomited in the bathroom mid lunch.\n",
       "979    I kept looking at the time and it had soon bec...\n",
       "980    I have been to very few places to eat that und...\n",
       "981    We started with the tuna sashimi which was bro...\n",
       "982                              Food was below average.\n",
       "983    It sure does beat the nachos at the movies but...\n",
       "984         All in all, Ha Long Bay was a bit of a flop.\n",
       "985    The problem I have is that they charge $11.99 ...\n",
       "986    Shrimp- When I unwrapped it (I live only 1/2 a...\n",
       "987       It lacked flavor, seemed undercooked, and dry.\n",
       "988    It really is impressive that the place hasn't ...\n",
       "989    I would avoid this place if you are staying in...\n",
       "990    The refried beans that came with my meal were ...\n",
       "991           Spend your money and time some place else.\n",
       "992    A lady at the table next to us found a live gr...\n",
       "993              the presentation of the food was awful.\n",
       "994             I can't tell you how disappointed I was.\n",
       "995    I think food should have flavor and texture an...\n",
       "996                             Appetite instantly gone.\n",
       "997    Overall I was not impressed and would not go b...\n",
       "998    The whole experience was underwhelming, and I ...\n",
       "999    Then, as if I hadn't wasted enough of my life ...\n",
       "Name: Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "Data=pd.read_csv('Restaurant_Reviews.tsv',delimiter='\\t')\n",
    "Data.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Duplicated Values: \n",
      " True\n",
      "\n",
      " Describe the data of Review : \n",
      "             Liked\n",
      "count  1000.00000\n",
      "mean      0.50000\n",
      "std       0.50025\n",
      "min       0.00000\n",
      "25%       0.00000\n",
      "50%       0.50000\n",
      "75%       1.00000\n",
      "max       1.00000\n",
      "\n",
      " Data Size :  1600\n"
     ]
    }
   ],
   "source": [
    "#Data.drop_duplicates(keep='first',inplace=True)\n",
    "print(\"\\n Duplicated Values: \\n\",Data.duplicated().any())\n",
    "print(\"\\n Describe the data of Review : \\n\", Data.describe())\n",
    "Data=Data.iloc[:800]\n",
    "print(\"\\n Data Size : \",Data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasti textur nasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select menu great price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get angri want damn pho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honeslti tast fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>potato like rubber could tell made ahead time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fri great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>great touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>servic prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>would go back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cashier care ever say still end wayyy overpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tri cape cod ravoli chicken cranberri mmmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disgust pretti sure human hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shock sign indic cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>highli recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>waitress littl slow servic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>place worth time let alon vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>burritto blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>food amaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>servic also cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>could care less interior beauti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>right red velvet cake ohhh stuff good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>never brought salad ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hole wall great mexican street taco friendli s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>took hour get food tabl restaur food luke warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>worst salmon sashimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>sashimi poor qualiti soggi tasteless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>great time famili dinner sunday night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>food tasti say real tradit hunan style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>bother slow servic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>flair bartend absolut amaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>frozen margarita way sugari tast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>good order twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>nutshel restaraunt smell like combin dirti fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>girlfriend veal bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>unfortun good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>pretti satifi experi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>join club get awesom offer via email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>perfect someon like beer ice cold case even co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>bland flavorless good way describ bare tepid meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>chain fan beat place easili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>nacho must</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>come back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>mani word say place everyth pretti well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>staff super nice quick even crazi crowd downto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>great atmospher friendli fast servic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>receiv pita huge lot meat thumb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>food arriv meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>pay hot dog fri look like came kid meal wiener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>classic main lobster roll fantast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>brother law work mall ate day guess sick night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>good go review place twice herea tribut place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>chip salsa realli good salsa fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>place great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>mediocr food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>get insid impress place</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                       wow love place\n",
       "1                                           crust good\n",
       "2                                   tasti textur nasti\n",
       "3    stop late may bank holiday rick steve recommen...\n",
       "4                              select menu great price\n",
       "5                              get angri want damn pho\n",
       "6                                  honeslti tast fresh\n",
       "7    potato like rubber could tell made ahead time ...\n",
       "8                                            fri great\n",
       "9                                          great touch\n",
       "10                                       servic prompt\n",
       "11                                       would go back\n",
       "12        cashier care ever say still end wayyy overpr\n",
       "13          tri cape cod ravoli chicken cranberri mmmm\n",
       "14                      disgust pretti sure human hair\n",
       "15                               shock sign indic cash\n",
       "16                                    highli recommend\n",
       "17                          waitress littl slow servic\n",
       "18                      place worth time let alon vega\n",
       "19                                                like\n",
       "20                                       burritto blah\n",
       "21                                           food amaz\n",
       "22                                    servic also cute\n",
       "23                     could care less interior beauti\n",
       "24                                             perform\n",
       "25               right red velvet cake ohhh stuff good\n",
       "26                             never brought salad ask\n",
       "27   hole wall great mexican street taco friendli s...\n",
       "28   took hour get food tabl restaur food luke warm...\n",
       "29                                worst salmon sashimi\n",
       "..                                                 ...\n",
       "770               sashimi poor qualiti soggi tasteless\n",
       "771              great time famili dinner sunday night\n",
       "772             food tasti say real tradit hunan style\n",
       "773                                 bother slow servic\n",
       "774                         flair bartend absolut amaz\n",
       "775                   frozen margarita way sugari tast\n",
       "776                                   good order twice\n",
       "777  nutshel restaraunt smell like combin dirti fis...\n",
       "778                                girlfriend veal bad\n",
       "779                                      unfortun good\n",
       "780                               pretti satifi experi\n",
       "781               join club get awesom offer via email\n",
       "782  perfect someon like beer ice cold case even co...\n",
       "783  bland flavorless good way describ bare tepid meat\n",
       "784                        chain fan beat place easili\n",
       "785                                         nacho must\n",
       "786                                          come back\n",
       "787            mani word say place everyth pretti well\n",
       "788  staff super nice quick even crazi crowd downto...\n",
       "789               great atmospher friendli fast servic\n",
       "790                    receiv pita huge lot meat thumb\n",
       "791                                     food arriv meh\n",
       "792  pay hot dog fri look like came kid meal wiener...\n",
       "793                  classic main lobster roll fantast\n",
       "794     brother law work mall ate day guess sick night\n",
       "795  good go review place twice herea tribut place ...\n",
       "796                 chip salsa realli good salsa fresh\n",
       "797                                        place great\n",
       "798                                       mediocr food\n",
       "799                            get insid impress place\n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # re library to clean data\n",
    "import nltk # Natural Language Tool Kit \n",
    "from nltk.corpus import stopwords # remove punctuation(stop words)\n",
    "from nltk.stem.porter import PorterStemmer # Steaming the words\n",
    "\n",
    "words=[]\n",
    "for word in range(0,800):\n",
    "    checking=re.sub('[^a-zA-Z]',\" \",Data['Review'][word])\n",
    "    checking=checking.lower()\n",
    "    checking=checking.split()\n",
    "    ps=PorterStemmer()\n",
    "    checking=[ps.stem(word) for word in checking\n",
    "                      if not word in set(stopwords.words('english'))]\n",
    "    checking=' '.join(checking)\n",
    "    words.append(checking)\n",
    "wordsN=pd.DataFrame(words)\n",
    "wordsN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None) \n",
      "   (0, 356)\t1\n",
      "  (0, 279)\t1\n",
      "  (0, 529)\t1\n",
      "  (1, 199)\t1\n",
      "  (1, 107)\t1\n",
      "  (2, 312)\t1\n",
      "  (2, 476)\t1\n",
      "  (2, 471)\t1\n",
      "  (3, 387)\t1\n",
      "  (3, 262)\t1\n",
      "  (3, 454)\t1\n",
      "  (3, 279)\t1\n",
      "  (4, 370)\t1\n",
      "  (4, 202)\t1\n",
      "  (4, 298)\t1\n",
      "  (4, 418)\t1\n",
      "  (5, 350)\t1\n",
      "  (5, 111)\t1\n",
      "  (5, 512)\t1\n",
      "  (6, 188)\t1\n",
      "  (6, 469)\t1\n",
      "  (7, 254)\t1\n",
      "  (7, 482)\t1\n",
      "  (7, 473)\t1\n",
      "  (7, 268)\t1\n",
      "  :\t:\n",
      "  (793, 398)\t1\n",
      "  (794, 285)\t1\n",
      "  (794, 525)\t1\n",
      "  (794, 114)\t1\n",
      "  (794, 17)\t1\n",
      "  (794, 318)\t1\n",
      "  (794, 209)\t1\n",
      "  (794, 426)\t1\n",
      "  (795, 495)\t1\n",
      "  (795, 157)\t1\n",
      "  (795, 394)\t1\n",
      "  (795, 318)\t1\n",
      "  (795, 199)\t1\n",
      "  (795, 356)\t2\n",
      "  (796, 83)\t1\n",
      "  (796, 383)\t1\n",
      "  (796, 188)\t1\n",
      "  (796, 199)\t1\n",
      "  (797, 202)\t1\n",
      "  (797, 356)\t1\n",
      "  (798, 295)\t1\n",
      "  (798, 187)\t1\n",
      "  (799, 243)\t1\n",
      "  (799, 248)\t1\n",
      "  (799, 356)\t1 \n",
      " (800, 535)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(lowercase=True,stop_words='english',min_df=2,max_features=1000)\n",
    "x=cv.fit_transform(words)\n",
    "y=Data.iloc[:,1].values\n",
    "print(cv,'\\n',x,'\\n',x.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolut',\n",
       " 'acknowledg',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'ago',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'ambianc',\n",
       " 'ambienc',\n",
       " 'anoth',\n",
       " 'anyon',\n",
       " 'anytim',\n",
       " 'appet',\n",
       " 'area',\n",
       " 'arriv',\n",
       " 'ask',\n",
       " 'assur',\n",
       " 'ate',\n",
       " 'atmospher',\n",
       " 'attack',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'authent',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'babi',\n",
       " 'bachi',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bakeri',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'bartend',\n",
       " 'basic',\n",
       " 'bathroom',\n",
       " 'batter',\n",
       " 'bay',\n",
       " 'bean',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'belli',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bisqu',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'bland',\n",
       " 'blow',\n",
       " 'boot',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'brick',\n",
       " 'bring',\n",
       " 'brought',\n",
       " 'brunch',\n",
       " 'buffet',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'busi',\n",
       " 'butter',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'came',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cashier',\n",
       " 'char',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'chees',\n",
       " 'cheeseburg',\n",
       " 'chef',\n",
       " 'chewi',\n",
       " 'chicken',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'choos',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'cocktail',\n",
       " 'coffe',\n",
       " 'cold',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comfort',\n",
       " 'compani',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'consid',\n",
       " 'conveni',\n",
       " 'cook',\n",
       " 'cool',\n",
       " 'coupl',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'cream',\n",
       " 'creami',\n",
       " 'crowd',\n",
       " 'crust',\n",
       " 'curri',\n",
       " 'custom',\n",
       " 'cute',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'decid',\n",
       " 'decor',\n",
       " 'definit',\n",
       " 'delici',\n",
       " 'delight',\n",
       " 'delish',\n",
       " 'deserv',\n",
       " 'dessert',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'dine',\n",
       " 'dinner',\n",
       " 'dirt',\n",
       " 'dirti',\n",
       " 'disappoint',\n",
       " 'disgrac',\n",
       " 'disgust',\n",
       " 'dish',\n",
       " 'dog',\n",
       " 'dont',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'downtown',\n",
       " 'dress',\n",
       " 'dri',\n",
       " 'driest',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'duck',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'edibl',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'els',\n",
       " 'elsewher',\n",
       " 'empti',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'especi',\n",
       " 'establish',\n",
       " 'event',\n",
       " 'everi',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'excel',\n",
       " 'excus',\n",
       " 'expect',\n",
       " 'experi',\n",
       " 'experienc',\n",
       " 'extra',\n",
       " 'extrem',\n",
       " 'eye',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'famili',\n",
       " 'familiar',\n",
       " 'fan',\n",
       " 'fantast',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'favorit',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'filet',\n",
       " 'final',\n",
       " 'fine',\n",
       " 'fish',\n",
       " 'flavor',\n",
       " 'flower',\n",
       " 'folk',\n",
       " 'food',\n",
       " 'fresh',\n",
       " 'fri',\n",
       " 'friend',\n",
       " 'friendli',\n",
       " 'frozen',\n",
       " 'fun',\n",
       " 'gave',\n",
       " 'gener',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'gold',\n",
       " 'good',\n",
       " 'got',\n",
       " 'greas',\n",
       " 'great',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greet',\n",
       " 'grill',\n",
       " 'gross',\n",
       " 'group',\n",
       " 'guess',\n",
       " 'guest',\n",
       " 'guy',\n",
       " 'gyro',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handl',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'hate',\n",
       " 'healthi',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'help',\n",
       " 'high',\n",
       " 'highli',\n",
       " 'hit',\n",
       " 'home',\n",
       " 'homemad',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'horribl',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'huge',\n",
       " 'hummu',\n",
       " 'husband',\n",
       " 'ice',\n",
       " 'ignor',\n",
       " 'imagin',\n",
       " 'immedi',\n",
       " 'impecc',\n",
       " 'impress',\n",
       " 'includ',\n",
       " 'incred',\n",
       " 'indian',\n",
       " 'inexpens',\n",
       " 'insid',\n",
       " 'insult',\n",
       " 'italian',\n",
       " 'job',\n",
       " 'joint',\n",
       " 'judg',\n",
       " 'kept',\n",
       " 'kid',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'known',\n",
       " 'lack',\n",
       " 'ladi',\n",
       " 'larg',\n",
       " 'late',\n",
       " 'later',\n",
       " 'leav',\n",
       " 'left',\n",
       " 'legit',\n",
       " 'let',\n",
       " 'like',\n",
       " 'list',\n",
       " 'liter',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'lobster',\n",
       " 'locat',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lover',\n",
       " 'lukewarm',\n",
       " 'lunch',\n",
       " 'main',\n",
       " 'make',\n",
       " 'mall',\n",
       " 'manag',\n",
       " 'mani',\n",
       " 'margarita',\n",
       " 'mari',\n",
       " 'mayb',\n",
       " 'mayo',\n",
       " 'meal',\n",
       " 'mean',\n",
       " 'meat',\n",
       " 'mediocr',\n",
       " 'meh',\n",
       " 'melt',\n",
       " 'menu',\n",
       " 'mexican',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'minut',\n",
       " 'miss',\n",
       " 'mistak',\n",
       " 'moist',\n",
       " 'mom',\n",
       " 'money',\n",
       " 'mood',\n",
       " 'mouth',\n",
       " 'multipl',\n",
       " 'music',\n",
       " 'nasti',\n",
       " 'need',\n",
       " 'neighborhood',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'nicest',\n",
       " 'night',\n",
       " 'non',\n",
       " 'note',\n",
       " 'noth',\n",
       " 'offer',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'opportun',\n",
       " 'option',\n",
       " 'order',\n",
       " 'outsid',\n",
       " 'outstand',\n",
       " 'oven',\n",
       " 'overal',\n",
       " 'overpr',\n",
       " 'overwhelm',\n",
       " 'owner',\n",
       " 'pancak',\n",
       " 'paper',\n",
       " 'par',\n",
       " 'parti',\n",
       " 'pass',\n",
       " 'pasta',\n",
       " 'patio',\n",
       " 'pay',\n",
       " 'peopl',\n",
       " 'pepper',\n",
       " 'perfect',\n",
       " 'perfectli',\n",
       " 'person',\n",
       " 'pho',\n",
       " 'phoenix',\n",
       " 'pictur',\n",
       " 'piec',\n",
       " 'pita',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'play',\n",
       " 'pleas',\n",
       " 'pleasant',\n",
       " 'plu',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'pop',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'possibl',\n",
       " 'potato',\n",
       " 'prepar',\n",
       " 'pretti',\n",
       " 'price',\n",
       " 'probabl',\n",
       " 'promis',\n",
       " 'provid',\n",
       " 'pull',\n",
       " 'qualiti',\n",
       " 'quick',\n",
       " 'quickli',\n",
       " 'quit',\n",
       " 'rare',\n",
       " 'rate',\n",
       " 'real',\n",
       " 'realiz',\n",
       " 'realli',\n",
       " 'reason',\n",
       " 'receiv',\n",
       " 'recent',\n",
       " 'recommend',\n",
       " 'red',\n",
       " 'regular',\n",
       " 'relax',\n",
       " 'remind',\n",
       " 'restaur',\n",
       " 'return',\n",
       " 'review',\n",
       " 'rice',\n",
       " 'right',\n",
       " 'roast',\n",
       " 'roll',\n",
       " 'rude',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'salad',\n",
       " 'salmon',\n",
       " 'salt',\n",
       " 'sandwich',\n",
       " 'sashimi',\n",
       " 'sat',\n",
       " 'satisfi',\n",
       " 'sauc',\n",
       " 'say',\n",
       " 'scallop',\n",
       " 'seafood',\n",
       " 'season',\n",
       " 'seat',\n",
       " 'second',\n",
       " 'seen',\n",
       " 'select',\n",
       " 'serv',\n",
       " 'server',\n",
       " 'servic',\n",
       " 'set',\n",
       " 'sever',\n",
       " 'shop',\n",
       " 'shrimp',\n",
       " 'sick',\n",
       " 'sign',\n",
       " 'similar',\n",
       " 'simpl',\n",
       " 'sinc',\n",
       " 'sit',\n",
       " 'slice',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smell',\n",
       " 'soggi',\n",
       " 'someon',\n",
       " 'someth',\n",
       " 'soon',\n",
       " 'soooo',\n",
       " 'sore',\n",
       " 'soup',\n",
       " 'special',\n",
       " 'spici',\n",
       " 'spot',\n",
       " 'staff',\n",
       " 'stale',\n",
       " 'star',\n",
       " 'station',\n",
       " 'stay',\n",
       " 'steak',\n",
       " 'step',\n",
       " 'stir',\n",
       " 'stop',\n",
       " 'strip',\n",
       " 'stuf',\n",
       " 'stuff',\n",
       " 'suck',\n",
       " 'sugari',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'sushi',\n",
       " 'sweet',\n",
       " 'tabl',\n",
       " 'taco',\n",
       " 'talk',\n",
       " 'tapa',\n",
       " 'tartar',\n",
       " 'tast',\n",
       " 'tasteless',\n",
       " 'tasti',\n",
       " 'tea',\n",
       " 'tell',\n",
       " 'tender',\n",
       " 'terribl',\n",
       " 'textur',\n",
       " 'thai',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'thumb',\n",
       " 'time',\n",
       " 'tip',\n",
       " 'toast',\n",
       " 'today',\n",
       " 'told',\n",
       " 'took',\n",
       " 'tot',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'treat',\n",
       " 'tri',\n",
       " 'trip',\n",
       " 'twice',\n",
       " 'unbeliev',\n",
       " 'unfortun',\n",
       " 'unless',\n",
       " 'use',\n",
       " 'valley',\n",
       " 'valu',\n",
       " 'vega',\n",
       " 'vegetarian',\n",
       " 'ventur',\n",
       " 'vinegrett',\n",
       " 'visit',\n",
       " 'wait',\n",
       " 'waiter',\n",
       " 'waitress',\n",
       " 'walk',\n",
       " 'wall',\n",
       " 'want',\n",
       " 'warm',\n",
       " 'wast',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'went',\n",
       " 'white',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'wing',\n",
       " 'wonder',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'wow',\n",
       " 'wrap',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'yummi',\n",
       " 'zero']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnames=cv.get_feature_names()\n",
    "xnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 535)\n",
      "   absolut  acknowledg  actual  ad  ago  alway  amaz  ambianc  ambienc  anoth  \\\n",
      "0        0           0       0   0    0      0     0        0        0      0   \n",
      "1        0           0       0   0    0      0     0        0        0      0   \n",
      "2        0           0       0   0    0      0     0        0        0      0   \n",
      "3        0           0       0   0    0      0     0        0        0      0   \n",
      "4        0           0       0   0    0      0     0        0        0      0   \n",
      "\n",
      "   ...   work  world  worst  worth  wow  wrap  wrong  year  yummi  zero  \n",
      "0  ...      0      0      0      0    1     0      0     0      0     0  \n",
      "1  ...      0      0      0      0    0     0      0     0      0     0  \n",
      "2  ...      0      0      0      0    0     0      0     0      0     0  \n",
      "3  ...      0      0      0      0    0     0      0     0      0     0  \n",
      "4  ...      0      0      0      0    0     0      0     0      0     0  \n",
      "\n",
      "[5 rows x 535 columns]\n"
     ]
    }
   ],
   "source": [
    "xcountname=pd.DataFrame(x.toarray(),columns=xnames)\n",
    "print(xcountname.shape)\n",
    "print(xcountname.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "LR=LogisticRegression()\n",
    "print(LR.fit(x_train,y_train))\n",
    "\n",
    "DT=DecisionTreeClassifier()\n",
    "print(DT.fit(x_train,y_train))\n",
    "\n",
    "SVC=SVC()\n",
    "print(SVC.fit(x_train,y_train))\n",
    "\n",
    "RF=RandomForestClassifier()\n",
    "print(RF.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix of Different Algorithm \n",
      "\n",
      " Logistic Regression : \n",
      " 0.725\n",
      "\n",
      " Support Vector Machine : \n",
      " 0.58125\n",
      "\n",
      " Random Forest : \n",
      " 0.70625\n",
      "\n",
      " Decision Tree : \n",
      " 0.7125\n",
      " Confusion Matrix of Different Algorithms \n",
      "\n",
      " Logistic Regression : \n",
      " [[44 21]\n",
      " [23 72]]\n",
      "\n",
      " Support Vector Machine : \n",
      " [[ 0  0]\n",
      " [67 93]]\n",
      "\n",
      " Random Forest : \n",
      " [[47 27]\n",
      " [20 66]]\n",
      "\n",
      " Decision Tree : \n",
      " [[39 18]\n",
      " [28 75]]\n",
      "  Classification Report of Different Algorithms \n",
      "\n",
      " Logistic Regression : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67        65\n",
      "           1       0.77      0.76      0.77        95\n",
      "\n",
      "   micro avg       0.72      0.72      0.73       160\n",
      "   macro avg       0.72      0.72      0.72       160\n",
      "weighted avg       0.73      0.72      0.73       160\n",
      "\n",
      "\n",
      " Support Vector Machine : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.58      0.74       160\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       160\n",
      "   macro avg       0.50      0.29      0.37       160\n",
      "weighted avg       1.00      0.58      0.74       160\n",
      "\n",
      "\n",
      " Random Forest : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        74\n",
      "           1       0.71      0.77      0.74        86\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       160\n",
      "   macro avg       0.71      0.70      0.70       160\n",
      "weighted avg       0.71      0.71      0.70       160\n",
      "\n",
      "\n",
      " Decision Tree : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63        57\n",
      "           1       0.81      0.73      0.77       103\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       160\n",
      "   macro avg       0.69      0.71      0.70       160\n",
      "weighted avg       0.73      0.71      0.72       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Prediction Different Algorithms\n",
    "\n",
    "LRPrediction= LR.predict(x_test)\n",
    "SVCPrediction=SVC.predict(x_test)\n",
    "RFPrediction=RF.predict(x_test)\n",
    "DTPrediction=DT.predict(x_test)\n",
    "\n",
    "print(\" Confusion Matrix of Different Algorithm \")\n",
    "print(\"\\n Logistic Regression : \\n\", accuracy_score(LRPrediction, y_test))\n",
    "print(\"\\n Support Vector Machine : \\n\", accuracy_score(SVCPrediction,y_test))\n",
    "print('\\n Random Forest : \\n', accuracy_score(RFPrediction,y_test))\n",
    "print('\\n Decision Tree : \\n',accuracy_score(DTPrediction,y_test))\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\" Confusion Matrix of Different Algorithms \")\n",
    "print(\"\\n Logistic Regression : \\n\", confusion_matrix(LRPrediction, y_test))\n",
    "print(\"\\n Support Vector Machine : \\n\", confusion_matrix(SVCPrediction,y_test))\n",
    "print('\\n Random Forest : \\n', confusion_matrix(RFPrediction,y_test))\n",
    "print('\\n Decision Tree : \\n',confusion_matrix(DTPrediction,y_test))\n",
    "\n",
    "# classification Report\n",
    "print(\"  Classification Report of Different Algorithms \")\n",
    "print(\"\\n Logistic Regression : \\n\", classification_report(LRPrediction, y_test))\n",
    "print(\"\\n Support Vector Machine : \\n\", classification_report(SVCPrediction,y_test))\n",
    "print('\\n Random Forest : \\n', classification_report(RFPrediction,y_test))\n",
    "print('\\n Decision Tree : \\n',classification_report(DTPrediction,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_prediction(review):\n",
    "    new_corpus = []\n",
    "    review = re.sub('[^a-zA-Z]', ' ' ,review)\n",
    "    #converting all characters to lowercase\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "   #loop for stemming each word in string array at ith row\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #rejoin all string array elements to create back into a string\n",
    "    review = ' '.join(review)\n",
    "    #append each string to create array of clean text\n",
    "    words.append(review)\n",
    "    count_vect = CountVectorizer(lowercase=True,stop_words='english',min_df=2,max_features = 10000)\n",
    "    x_count_vect = count_vect.fit_transform(words + new_corpus).toarray()\n",
    "    x = x_count_vect[-1].reshape(1, -1)\n",
    "    prediction = LR.predict(x)\n",
    "    if prediction == 1:\n",
    "        return \"Positive Review\"\n",
    "    else:\n",
    "        return \"Negative Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeling good to live in Mumbai\n",
      "Positive Review\n"
     ]
    }
   ],
   "source": [
    "# Positive Review\n",
    "print(review_prediction(input()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel Worst journey \n",
      "Negative Review\n"
     ]
    }
   ],
   "source": [
    "# Negaive_Review\n",
    "print(review_prediction(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_prediction(input()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
