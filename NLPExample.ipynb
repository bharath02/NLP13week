{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk # Natural Language tool kit\n",
    "import nltk.corpus # All data set of Natural Language tool Kit store in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pe08', 'pe08.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora'))) # list of NLTK librarys and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words() # read list of words present in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids() # list of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt') # Reading database Shakespeare-hamlet.txt \n",
    "print(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]: # Top 500 words in  Shakespeare dataset\n",
    "    print(word,end=\" \",sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet1=\"\"\"In this part of the tutorial, I want us to take a moment to peak into the corpora we all downloaded! The NLTK corpus is a massive dump of all kinds of natural language data sets that are definitely worth taking a look at.\n",
    "\n",
    "Almost all of the files in the NLTK corpus follow the same rules for accessing them by using the NLTK module, but nothing is magical about them. These files are plain text files for the most part, some are XML and some are other formats, but they are all accessible by you manually, or via the module and Python. Lets talk about viewing them manually.\n",
    "\n",
    "Depending on your installation, your nltk_data directory might be hiding in a multitude of locations. To figure out where it is, head to your Python directory, where the NLTK module is. If you do not know where that is, use the following code:\n",
    "\n",
    "\n",
    "Run that, and the output will be the location of the NLTK module's __init__.py. Head into the NLTK directory, and then look for the data.py file.\n",
    "\n",
    "The important blurb of code is:\n",
    "\n",
    "There, you can see the various possible directories for the nltk_data. If you're on Windows, chances are it is in your appdata, in the local directory. To get there, you will want to open your file browser, go to the top, and type in %appdata%\n",
    "\n",
    "Next click on roaming, and then find the nltk_data directory. In there, you will have your corpora file. The full path is something like:\n",
    "\n",
    "Within here, you have all of the available corpora, including things like books, chat logs, movie reviews, and a whole lot more.\n",
    "\n",
    "Now, we're going to talk about accessing these documents via NLTK. As you can see, these are mostly text documents, so you could just use normal Python code to open and read documents. That said, the NLTK module has a few nice methods for handling the corpus, so you may find it useful to use their methology. Heres an example of us opening the Gutenberg Bible, and reading the first few lines:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hamlet1) # The data should be in str or byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'this', 'part', 'of', 'the', 'tutorial', ',', 'I', 'want', 'us', 'to', 'take', 'a', 'moment', 'to', 'peak', 'into', 'the', 'corpora', 'we', 'all', 'downloaded', '!', 'The', 'NLTK', 'corpus', 'is', 'a', 'massive', 'dump', 'of', 'all', 'kinds', 'of', 'natural', 'language', 'data', 'sets', 'that', 'are', 'definitely', 'worth', 'taking', 'a', 'look', 'at', '.', 'Almost', 'all', 'of', 'the', 'files', 'in', 'the', 'NLTK', 'corpus', 'follow', 'the', 'same', 'rules', 'for', 'accessing', 'them', 'by', 'using', 'the', 'NLTK', 'module', ',', 'but', 'nothing', 'is', 'magical', 'about', 'them', '.', 'These', 'files', 'are', 'plain', 'text', 'files', 'for', 'the', 'most', 'part', ',', 'some', 'are', 'XML', 'and', 'some', 'are', 'other', 'formats', ',', 'but', 'they', 'are', 'all', 'accessible', 'by', 'you', 'manually', ',', 'or', 'via', 'the', 'module', 'and', 'Python', '.', 'Lets', 'talk', 'about', 'viewing', 'them', 'manually', '.', 'Depending', 'on', 'your', 'installation', ',', 'your', 'nltk_data', 'directory', 'might', 'be', 'hiding', 'in', 'a', 'multitude', 'of', 'locations', '.', 'To', 'figure', 'out', 'where', 'it', 'is', ',', 'head', 'to', 'your', 'Python', 'directory', ',', 'where', 'the', 'NLTK', 'module', 'is', '.', 'If', 'you', 'do', 'not', 'know', 'where', 'that', 'is', ',', 'use', 'the', 'following', 'code', ':', 'Run', 'that', ',', 'and', 'the', 'output', 'will', 'be', 'the', 'location', 'of', 'the', 'NLTK', 'module', \"'s\", '__init__.py', '.', 'Head', 'into', 'the', 'NLTK', 'directory', ',', 'and', 'then', 'look', 'for', 'the', 'data.py', 'file', '.', 'The', 'important', 'blurb', 'of', 'code', 'is', ':', 'There', ',', 'you', 'can', 'see', 'the', 'various', 'possible', 'directories', 'for', 'the', 'nltk_data', '.', 'If', 'you', \"'re\", 'on', 'Windows', ',', 'chances', 'are', 'it', 'is', 'in', 'your', 'appdata', ',', 'in', 'the', 'local', 'directory', '.', 'To', 'get', 'there', ',', 'you', 'will', 'want', 'to', 'open', 'your', 'file', 'browser', ',', 'go', 'to', 'the', 'top', ',', 'and', 'type', 'in', '%', 'appdata', '%', 'Next', 'click', 'on', 'roaming', ',', 'and', 'then', 'find', 'the', 'nltk_data', 'directory', '.', 'In', 'there', ',', 'you', 'will', 'have', 'your', 'corpora', 'file', '.', 'The', 'full', 'path', 'is', 'something', 'like', ':', 'Within', 'here', ',', 'you', 'have', 'all', 'of', 'the', 'available', 'corpora', ',', 'including', 'things', 'like', 'books', ',', 'chat', 'logs', ',', 'movie', 'reviews', ',', 'and', 'a', 'whole', 'lot', 'more', '.', 'Now', ',', 'we', \"'re\", 'going', 'to', 'talk', 'about', 'accessing', 'these', 'documents', 'via', 'NLTK', '.', 'As', 'you', 'can', 'see', ',', 'these', 'are', 'mostly', 'text', 'documents', ',', 'so', 'you', 'could', 'just', 'use', 'normal', 'Python', 'code', 'to', 'open', 'and', 'read', 'documents', '.', 'That', 'said', ',', 'the', 'NLTK', 'module', 'has', 'a', 'few', 'nice', 'methods', 'for', 'handling', 'the', 'corpus', ',', 'so', 'you', 'may', 'find', 'it', 'useful', 'to', 'use', 'their', 'methology', '.', 'Heres', 'an', 'example', 'of', 'us', 'opening', 'the', 'Gutenberg', 'Bible', ',', 'and', 'reading', 'the', 'first', 'few', 'lines', ':']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize # using a token Library to paragraph\n",
    "tokenWord=word_tokenize(hamlet1) # giving a token to set of paragraph\n",
    "print(tokenWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'!': 1,\n",
       "          '%': 2,\n",
       "          \"'re\": 2,\n",
       "          \"'s\": 1,\n",
       "          ',': 30,\n",
       "          '.': 16,\n",
       "          ':': 4,\n",
       "          '__init__.py': 1,\n",
       "          'a': 6,\n",
       "          'about': 3,\n",
       "          'accessible': 1,\n",
       "          'accessing': 2,\n",
       "          'all': 5,\n",
       "          'almost': 1,\n",
       "          'an': 1,\n",
       "          'and': 9,\n",
       "          'appdata': 2,\n",
       "          'are': 7,\n",
       "          'as': 1,\n",
       "          'at': 1,\n",
       "          'available': 1,\n",
       "          'be': 2,\n",
       "          'bible': 1,\n",
       "          'blurb': 1,\n",
       "          'books': 1,\n",
       "          'browser': 1,\n",
       "          'but': 2,\n",
       "          'by': 2,\n",
       "          'can': 2,\n",
       "          'chances': 1,\n",
       "          'chat': 1,\n",
       "          'click': 1,\n",
       "          'code': 3,\n",
       "          'corpora': 3,\n",
       "          'corpus': 3,\n",
       "          'could': 1,\n",
       "          'data': 1,\n",
       "          'data.py': 1,\n",
       "          'definitely': 1,\n",
       "          'depending': 1,\n",
       "          'directories': 1,\n",
       "          'directory': 5,\n",
       "          'do': 1,\n",
       "          'documents': 3,\n",
       "          'downloaded': 1,\n",
       "          'dump': 1,\n",
       "          'example': 1,\n",
       "          'few': 2,\n",
       "          'figure': 1,\n",
       "          'file': 3,\n",
       "          'files': 3,\n",
       "          'find': 2,\n",
       "          'first': 1,\n",
       "          'follow': 1,\n",
       "          'following': 1,\n",
       "          'for': 5,\n",
       "          'formats': 1,\n",
       "          'full': 1,\n",
       "          'get': 1,\n",
       "          'go': 1,\n",
       "          'going': 1,\n",
       "          'gutenberg': 1,\n",
       "          'handling': 1,\n",
       "          'has': 1,\n",
       "          'have': 2,\n",
       "          'head': 2,\n",
       "          'here': 1,\n",
       "          'heres': 1,\n",
       "          'hiding': 1,\n",
       "          'i': 1,\n",
       "          'if': 2,\n",
       "          'important': 1,\n",
       "          'in': 7,\n",
       "          'including': 1,\n",
       "          'installation': 1,\n",
       "          'into': 2,\n",
       "          'is': 8,\n",
       "          'it': 3,\n",
       "          'just': 1,\n",
       "          'kinds': 1,\n",
       "          'know': 1,\n",
       "          'language': 1,\n",
       "          'lets': 1,\n",
       "          'like': 2,\n",
       "          'lines': 1,\n",
       "          'local': 1,\n",
       "          'location': 1,\n",
       "          'locations': 1,\n",
       "          'logs': 1,\n",
       "          'look': 2,\n",
       "          'lot': 1,\n",
       "          'magical': 1,\n",
       "          'manually': 2,\n",
       "          'massive': 1,\n",
       "          'may': 1,\n",
       "          'methods': 1,\n",
       "          'methology': 1,\n",
       "          'might': 1,\n",
       "          'module': 5,\n",
       "          'moment': 1,\n",
       "          'more': 1,\n",
       "          'most': 1,\n",
       "          'mostly': 1,\n",
       "          'movie': 1,\n",
       "          'multitude': 1,\n",
       "          'natural': 1,\n",
       "          'next': 1,\n",
       "          'nice': 1,\n",
       "          'nltk': 8,\n",
       "          'nltk_data': 3,\n",
       "          'normal': 1,\n",
       "          'not': 1,\n",
       "          'nothing': 1,\n",
       "          'now': 1,\n",
       "          'of': 9,\n",
       "          'on': 3,\n",
       "          'open': 2,\n",
       "          'opening': 1,\n",
       "          'or': 1,\n",
       "          'other': 1,\n",
       "          'out': 1,\n",
       "          'output': 1,\n",
       "          'part': 2,\n",
       "          'path': 1,\n",
       "          'peak': 1,\n",
       "          'plain': 1,\n",
       "          'possible': 1,\n",
       "          'python': 3,\n",
       "          'read': 1,\n",
       "          'reading': 1,\n",
       "          'reviews': 1,\n",
       "          'roaming': 1,\n",
       "          'rules': 1,\n",
       "          'run': 1,\n",
       "          'said': 1,\n",
       "          'same': 1,\n",
       "          'see': 2,\n",
       "          'sets': 1,\n",
       "          'so': 2,\n",
       "          'some': 2,\n",
       "          'something': 1,\n",
       "          'take': 1,\n",
       "          'taking': 1,\n",
       "          'talk': 2,\n",
       "          'text': 2,\n",
       "          'that': 4,\n",
       "          'the': 28,\n",
       "          'their': 1,\n",
       "          'them': 3,\n",
       "          'then': 2,\n",
       "          'there': 3,\n",
       "          'these': 3,\n",
       "          'they': 1,\n",
       "          'things': 1,\n",
       "          'this': 1,\n",
       "          'to': 10,\n",
       "          'top': 1,\n",
       "          'tutorial': 1,\n",
       "          'type': 1,\n",
       "          'us': 2,\n",
       "          'use': 3,\n",
       "          'useful': 1,\n",
       "          'using': 1,\n",
       "          'various': 1,\n",
       "          'via': 2,\n",
       "          'viewing': 1,\n",
       "          'want': 2,\n",
       "          'we': 2,\n",
       "          'where': 3,\n",
       "          'whole': 1,\n",
       "          'will': 3,\n",
       "          'windows': 1,\n",
       "          'within': 1,\n",
       "          'worth': 1,\n",
       "          'xml': 1,\n",
       "          'you': 10,\n",
       "          'your': 6})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenWord)\n",
    "from nltk.probability import FreqDist # words count or probabilty of a program.\n",
    "fdist=FreqDist()\n",
    "for word in tokenWord:\n",
    "    fdist[word.lower()]+=1\n",
    "    \n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 177 samples and 403 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 30),\n",
       " ('the', 28),\n",
       " ('.', 16),\n",
       " ('to', 10),\n",
       " ('you', 10),\n",
       " ('of', 9),\n",
       " ('and', 9),\n",
       " ('nltk', 8),\n",
       " ('is', 8),\n",
       " ('in', 7)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fdist)\n",
    "fdist10=fdist.most_common(10)\n",
    "fdist10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize # Check the total lines in Paragraph \n",
    "linesINParagraph=blankline_tokenize(hamlet1)\n",
    "print(len(linesINParagraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Depending on your installation, your nltk_data directory might be hiding in a multitude of locations. To figure out where it is, head to your Python directory, where the NLTK module is. If you do not know where that is, use the following code:'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineINParagraph[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'this'),\n",
       " ('this', 'part'),\n",
       " ('part', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'tutorial'),\n",
       " ('tutorial', ','),\n",
       " (',', 'i'),\n",
       " ('i', 'want'),\n",
       " ('want', 'us'),\n",
       " ('us', 'to'),\n",
       " ('to', 'take'),\n",
       " ('take', 'a'),\n",
       " ('a', 'moment'),\n",
       " ('moment', 'peak'),\n",
       " ('peak', 'into'),\n",
       " ('into', 'corpora'),\n",
       " ('corpora', 'we'),\n",
       " ('we', 'all'),\n",
       " ('all', 'downloaded'),\n",
       " ('downloaded', '!'),\n",
       " ('!', 'nltk'),\n",
       " ('nltk', 'corpus'),\n",
       " ('corpus', 'is'),\n",
       " ('is', 'massive'),\n",
       " ('massive', 'dump'),\n",
       " ('dump', 'kinds'),\n",
       " ('kinds', 'natural'),\n",
       " ('natural', 'language'),\n",
       " ('language', 'data'),\n",
       " ('data', 'sets'),\n",
       " ('sets', 'that'),\n",
       " ('that', 'are'),\n",
       " ('are', 'definitely'),\n",
       " ('definitely', 'worth'),\n",
       " ('worth', 'taking'),\n",
       " ('taking', 'look'),\n",
       " ('look', 'at'),\n",
       " ('at', '.'),\n",
       " ('.', 'almost'),\n",
       " ('almost', 'files'),\n",
       " ('files', 'follow'),\n",
       " ('follow', 'same'),\n",
       " ('same', 'rules'),\n",
       " ('rules', 'for'),\n",
       " ('for', 'accessing'),\n",
       " ('accessing', 'them'),\n",
       " ('them', 'by'),\n",
       " ('by', 'using'),\n",
       " ('using', 'module'),\n",
       " ('module', 'but'),\n",
       " ('but', 'nothing'),\n",
       " ('nothing', 'magical'),\n",
       " ('magical', 'about'),\n",
       " ('about', 'these'),\n",
       " ('these', 'plain'),\n",
       " ('plain', 'text'),\n",
       " ('text', 'most'),\n",
       " ('most', 'some'),\n",
       " ('some', 'xml'),\n",
       " ('xml', 'and'),\n",
       " ('and', 'other'),\n",
       " ('other', 'formats'),\n",
       " ('formats', 'they'),\n",
       " ('they', 'accessible'),\n",
       " ('accessible', 'you'),\n",
       " ('you', 'manually'),\n",
       " ('manually', 'or'),\n",
       " ('or', 'via'),\n",
       " ('via', 'python'),\n",
       " ('python', 'lets'),\n",
       " ('lets', 'talk'),\n",
       " ('talk', 'viewing'),\n",
       " ('viewing', 'depending'),\n",
       " ('depending', 'on'),\n",
       " ('on', 'your'),\n",
       " ('your', 'installation'),\n",
       " ('installation', 'nltk_data'),\n",
       " ('nltk_data', 'directory'),\n",
       " ('directory', 'might'),\n",
       " ('might', 'be'),\n",
       " ('be', 'hiding'),\n",
       " ('hiding', 'multitude'),\n",
       " ('multitude', 'locations'),\n",
       " ('locations', 'figure'),\n",
       " ('figure', 'out'),\n",
       " ('out', 'where'),\n",
       " ('where', 'it'),\n",
       " ('it', 'head'),\n",
       " ('head', 'if'),\n",
       " ('if', 'do'),\n",
       " ('do', 'not'),\n",
       " ('not', 'know'),\n",
       " ('know', 'use'),\n",
       " ('use', 'following'),\n",
       " ('following', 'code'),\n",
       " ('code', ':'),\n",
       " (':', 'run'),\n",
       " ('run', 'output'),\n",
       " ('output', 'will'),\n",
       " ('will', 'location'),\n",
       " ('location', \"'s\"),\n",
       " (\"'s\", '__init__.py'),\n",
       " ('__init__.py', 'then'),\n",
       " ('then', 'data.py'),\n",
       " ('data.py', 'file'),\n",
       " ('file', 'important'),\n",
       " ('important', 'blurb'),\n",
       " ('blurb', 'there'),\n",
       " ('there', 'can'),\n",
       " ('can', 'see'),\n",
       " ('see', 'various'),\n",
       " ('various', 'possible'),\n",
       " ('possible', 'directories'),\n",
       " ('directories', \"'re\"),\n",
       " (\"'re\", 'windows'),\n",
       " ('windows', 'chances'),\n",
       " ('chances', 'appdata'),\n",
       " ('appdata', 'local'),\n",
       " ('local', 'get'),\n",
       " ('get', 'open'),\n",
       " ('open', 'browser'),\n",
       " ('browser', 'go'),\n",
       " ('go', 'top'),\n",
       " ('top', 'type'),\n",
       " ('type', '%'),\n",
       " ('%', 'next'),\n",
       " ('next', 'click'),\n",
       " ('click', 'roaming'),\n",
       " ('roaming', 'find'),\n",
       " ('find', 'have'),\n",
       " ('have', 'full'),\n",
       " ('full', 'path'),\n",
       " ('path', 'something'),\n",
       " ('something', 'like'),\n",
       " ('like', 'within'),\n",
       " ('within', 'here'),\n",
       " ('here', 'available'),\n",
       " ('available', 'including'),\n",
       " ('including', 'things'),\n",
       " ('things', 'books'),\n",
       " ('books', 'chat'),\n",
       " ('chat', 'logs'),\n",
       " ('logs', 'movie'),\n",
       " ('movie', 'reviews'),\n",
       " ('reviews', 'whole'),\n",
       " ('whole', 'lot'),\n",
       " ('lot', 'more'),\n",
       " ('more', 'now'),\n",
       " ('now', 'going'),\n",
       " ('going', 'documents'),\n",
       " ('documents', 'as'),\n",
       " ('as', 'mostly'),\n",
       " ('mostly', 'so'),\n",
       " ('so', 'could'),\n",
       " ('could', 'just'),\n",
       " ('just', 'normal'),\n",
       " ('normal', 'read'),\n",
       " ('read', 'said'),\n",
       " ('said', 'has'),\n",
       " ('has', 'few'),\n",
       " ('few', 'nice'),\n",
       " ('nice', 'methods'),\n",
       " ('methods', 'handling'),\n",
       " ('handling', 'may'),\n",
       " ('may', 'useful'),\n",
       " ('useful', 'their'),\n",
       " ('their', 'methology'),\n",
       " ('methology', 'heres'),\n",
       " ('heres', 'an'),\n",
       " ('an', 'example'),\n",
       " ('example', 'opening'),\n",
       " ('opening', 'gutenberg'),\n",
       " ('gutenberg', 'bible'),\n",
       " ('bible', 'reading'),\n",
       " ('reading', 'first'),\n",
       " ('first', 'lines')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "There are three types of tokenization functions in NLTK\n",
    "    1 . \"Biagram\" Two words from paragraph to tokenization\n",
    "    2 . \"Trigrams\" three words from paragraph to tokenization\n",
    "    3 . \"Three words from a paragraphs to tokenizations\n",
    "    \n",
    "\"\"\" \n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "\n",
    "twoWords=list(nltk.bigrams(fdist))\n",
    "twoWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'this', 'part'),\n",
       " ('this', 'part', 'of'),\n",
       " ('part', 'of', 'the'),\n",
       " ('of', 'the', 'tutorial'),\n",
       " ('the', 'tutorial', ','),\n",
       " ('tutorial', ',', 'i'),\n",
       " (',', 'i', 'want'),\n",
       " ('i', 'want', 'us'),\n",
       " ('want', 'us', 'to'),\n",
       " ('us', 'to', 'take'),\n",
       " ('to', 'take', 'a'),\n",
       " ('take', 'a', 'moment'),\n",
       " ('a', 'moment', 'peak'),\n",
       " ('moment', 'peak', 'into'),\n",
       " ('peak', 'into', 'corpora'),\n",
       " ('into', 'corpora', 'we'),\n",
       " ('corpora', 'we', 'all'),\n",
       " ('we', 'all', 'downloaded'),\n",
       " ('all', 'downloaded', '!'),\n",
       " ('downloaded', '!', 'nltk'),\n",
       " ('!', 'nltk', 'corpus'),\n",
       " ('nltk', 'corpus', 'is'),\n",
       " ('corpus', 'is', 'massive'),\n",
       " ('is', 'massive', 'dump'),\n",
       " ('massive', 'dump', 'kinds'),\n",
       " ('dump', 'kinds', 'natural'),\n",
       " ('kinds', 'natural', 'language'),\n",
       " ('natural', 'language', 'data'),\n",
       " ('language', 'data', 'sets'),\n",
       " ('data', 'sets', 'that'),\n",
       " ('sets', 'that', 'are'),\n",
       " ('that', 'are', 'definitely'),\n",
       " ('are', 'definitely', 'worth'),\n",
       " ('definitely', 'worth', 'taking'),\n",
       " ('worth', 'taking', 'look'),\n",
       " ('taking', 'look', 'at'),\n",
       " ('look', 'at', '.'),\n",
       " ('at', '.', 'almost'),\n",
       " ('.', 'almost', 'files'),\n",
       " ('almost', 'files', 'follow'),\n",
       " ('files', 'follow', 'same'),\n",
       " ('follow', 'same', 'rules'),\n",
       " ('same', 'rules', 'for'),\n",
       " ('rules', 'for', 'accessing'),\n",
       " ('for', 'accessing', 'them'),\n",
       " ('accessing', 'them', 'by'),\n",
       " ('them', 'by', 'using'),\n",
       " ('by', 'using', 'module'),\n",
       " ('using', 'module', 'but'),\n",
       " ('module', 'but', 'nothing'),\n",
       " ('but', 'nothing', 'magical'),\n",
       " ('nothing', 'magical', 'about'),\n",
       " ('magical', 'about', 'these'),\n",
       " ('about', 'these', 'plain'),\n",
       " ('these', 'plain', 'text'),\n",
       " ('plain', 'text', 'most'),\n",
       " ('text', 'most', 'some'),\n",
       " ('most', 'some', 'xml'),\n",
       " ('some', 'xml', 'and'),\n",
       " ('xml', 'and', 'other'),\n",
       " ('and', 'other', 'formats'),\n",
       " ('other', 'formats', 'they'),\n",
       " ('formats', 'they', 'accessible'),\n",
       " ('they', 'accessible', 'you'),\n",
       " ('accessible', 'you', 'manually'),\n",
       " ('you', 'manually', 'or'),\n",
       " ('manually', 'or', 'via'),\n",
       " ('or', 'via', 'python'),\n",
       " ('via', 'python', 'lets'),\n",
       " ('python', 'lets', 'talk'),\n",
       " ('lets', 'talk', 'viewing'),\n",
       " ('talk', 'viewing', 'depending'),\n",
       " ('viewing', 'depending', 'on'),\n",
       " ('depending', 'on', 'your'),\n",
       " ('on', 'your', 'installation'),\n",
       " ('your', 'installation', 'nltk_data'),\n",
       " ('installation', 'nltk_data', 'directory'),\n",
       " ('nltk_data', 'directory', 'might'),\n",
       " ('directory', 'might', 'be'),\n",
       " ('might', 'be', 'hiding'),\n",
       " ('be', 'hiding', 'multitude'),\n",
       " ('hiding', 'multitude', 'locations'),\n",
       " ('multitude', 'locations', 'figure'),\n",
       " ('locations', 'figure', 'out'),\n",
       " ('figure', 'out', 'where'),\n",
       " ('out', 'where', 'it'),\n",
       " ('where', 'it', 'head'),\n",
       " ('it', 'head', 'if'),\n",
       " ('head', 'if', 'do'),\n",
       " ('if', 'do', 'not'),\n",
       " ('do', 'not', 'know'),\n",
       " ('not', 'know', 'use'),\n",
       " ('know', 'use', 'following'),\n",
       " ('use', 'following', 'code'),\n",
       " ('following', 'code', ':'),\n",
       " ('code', ':', 'run'),\n",
       " (':', 'run', 'output'),\n",
       " ('run', 'output', 'will'),\n",
       " ('output', 'will', 'location'),\n",
       " ('will', 'location', \"'s\"),\n",
       " ('location', \"'s\", '__init__.py'),\n",
       " (\"'s\", '__init__.py', 'then'),\n",
       " ('__init__.py', 'then', 'data.py'),\n",
       " ('then', 'data.py', 'file'),\n",
       " ('data.py', 'file', 'important'),\n",
       " ('file', 'important', 'blurb'),\n",
       " ('important', 'blurb', 'there'),\n",
       " ('blurb', 'there', 'can'),\n",
       " ('there', 'can', 'see'),\n",
       " ('can', 'see', 'various'),\n",
       " ('see', 'various', 'possible'),\n",
       " ('various', 'possible', 'directories'),\n",
       " ('possible', 'directories', \"'re\"),\n",
       " ('directories', \"'re\", 'windows'),\n",
       " (\"'re\", 'windows', 'chances'),\n",
       " ('windows', 'chances', 'appdata'),\n",
       " ('chances', 'appdata', 'local'),\n",
       " ('appdata', 'local', 'get'),\n",
       " ('local', 'get', 'open'),\n",
       " ('get', 'open', 'browser'),\n",
       " ('open', 'browser', 'go'),\n",
       " ('browser', 'go', 'top'),\n",
       " ('go', 'top', 'type'),\n",
       " ('top', 'type', '%'),\n",
       " ('type', '%', 'next'),\n",
       " ('%', 'next', 'click'),\n",
       " ('next', 'click', 'roaming'),\n",
       " ('click', 'roaming', 'find'),\n",
       " ('roaming', 'find', 'have'),\n",
       " ('find', 'have', 'full'),\n",
       " ('have', 'full', 'path'),\n",
       " ('full', 'path', 'something'),\n",
       " ('path', 'something', 'like'),\n",
       " ('something', 'like', 'within'),\n",
       " ('like', 'within', 'here'),\n",
       " ('within', 'here', 'available'),\n",
       " ('here', 'available', 'including'),\n",
       " ('available', 'including', 'things'),\n",
       " ('including', 'things', 'books'),\n",
       " ('things', 'books', 'chat'),\n",
       " ('books', 'chat', 'logs'),\n",
       " ('chat', 'logs', 'movie'),\n",
       " ('logs', 'movie', 'reviews'),\n",
       " ('movie', 'reviews', 'whole'),\n",
       " ('reviews', 'whole', 'lot'),\n",
       " ('whole', 'lot', 'more'),\n",
       " ('lot', 'more', 'now'),\n",
       " ('more', 'now', 'going'),\n",
       " ('now', 'going', 'documents'),\n",
       " ('going', 'documents', 'as'),\n",
       " ('documents', 'as', 'mostly'),\n",
       " ('as', 'mostly', 'so'),\n",
       " ('mostly', 'so', 'could'),\n",
       " ('so', 'could', 'just'),\n",
       " ('could', 'just', 'normal'),\n",
       " ('just', 'normal', 'read'),\n",
       " ('normal', 'read', 'said'),\n",
       " ('read', 'said', 'has'),\n",
       " ('said', 'has', 'few'),\n",
       " ('has', 'few', 'nice'),\n",
       " ('few', 'nice', 'methods'),\n",
       " ('nice', 'methods', 'handling'),\n",
       " ('methods', 'handling', 'may'),\n",
       " ('handling', 'may', 'useful'),\n",
       " ('may', 'useful', 'their'),\n",
       " ('useful', 'their', 'methology'),\n",
       " ('their', 'methology', 'heres'),\n",
       " ('methology', 'heres', 'an'),\n",
       " ('heres', 'an', 'example'),\n",
       " ('an', 'example', 'opening'),\n",
       " ('example', 'opening', 'gutenberg'),\n",
       " ('opening', 'gutenberg', 'bible'),\n",
       " ('gutenberg', 'bible', 'reading'),\n",
       " ('bible', 'reading', 'first'),\n",
       " ('reading', 'first', 'lines')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threeWord=list(nltk.trigrams(fdist))\n",
    "threeWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'this', 'part', 'of', 'the', 'tutorial'),\n",
       " ('this', 'part', 'of', 'the', 'tutorial', ','),\n",
       " ('part', 'of', 'the', 'tutorial', ',', 'i'),\n",
       " ('of', 'the', 'tutorial', ',', 'i', 'want'),\n",
       " ('the', 'tutorial', ',', 'i', 'want', 'us'),\n",
       " ('tutorial', ',', 'i', 'want', 'us', 'to'),\n",
       " (',', 'i', 'want', 'us', 'to', 'take'),\n",
       " ('i', 'want', 'us', 'to', 'take', 'a'),\n",
       " ('want', 'us', 'to', 'take', 'a', 'moment'),\n",
       " ('us', 'to', 'take', 'a', 'moment', 'peak'),\n",
       " ('to', 'take', 'a', 'moment', 'peak', 'into'),\n",
       " ('take', 'a', 'moment', 'peak', 'into', 'corpora'),\n",
       " ('a', 'moment', 'peak', 'into', 'corpora', 'we'),\n",
       " ('moment', 'peak', 'into', 'corpora', 'we', 'all'),\n",
       " ('peak', 'into', 'corpora', 'we', 'all', 'downloaded'),\n",
       " ('into', 'corpora', 'we', 'all', 'downloaded', '!'),\n",
       " ('corpora', 'we', 'all', 'downloaded', '!', 'nltk'),\n",
       " ('we', 'all', 'downloaded', '!', 'nltk', 'corpus'),\n",
       " ('all', 'downloaded', '!', 'nltk', 'corpus', 'is'),\n",
       " ('downloaded', '!', 'nltk', 'corpus', 'is', 'massive'),\n",
       " ('!', 'nltk', 'corpus', 'is', 'massive', 'dump'),\n",
       " ('nltk', 'corpus', 'is', 'massive', 'dump', 'kinds'),\n",
       " ('corpus', 'is', 'massive', 'dump', 'kinds', 'natural'),\n",
       " ('is', 'massive', 'dump', 'kinds', 'natural', 'language'),\n",
       " ('massive', 'dump', 'kinds', 'natural', 'language', 'data'),\n",
       " ('dump', 'kinds', 'natural', 'language', 'data', 'sets'),\n",
       " ('kinds', 'natural', 'language', 'data', 'sets', 'that'),\n",
       " ('natural', 'language', 'data', 'sets', 'that', 'are'),\n",
       " ('language', 'data', 'sets', 'that', 'are', 'definitely'),\n",
       " ('data', 'sets', 'that', 'are', 'definitely', 'worth'),\n",
       " ('sets', 'that', 'are', 'definitely', 'worth', 'taking'),\n",
       " ('that', 'are', 'definitely', 'worth', 'taking', 'look'),\n",
       " ('are', 'definitely', 'worth', 'taking', 'look', 'at'),\n",
       " ('definitely', 'worth', 'taking', 'look', 'at', '.'),\n",
       " ('worth', 'taking', 'look', 'at', '.', 'almost'),\n",
       " ('taking', 'look', 'at', '.', 'almost', 'files'),\n",
       " ('look', 'at', '.', 'almost', 'files', 'follow'),\n",
       " ('at', '.', 'almost', 'files', 'follow', 'same'),\n",
       " ('.', 'almost', 'files', 'follow', 'same', 'rules'),\n",
       " ('almost', 'files', 'follow', 'same', 'rules', 'for'),\n",
       " ('files', 'follow', 'same', 'rules', 'for', 'accessing'),\n",
       " ('follow', 'same', 'rules', 'for', 'accessing', 'them'),\n",
       " ('same', 'rules', 'for', 'accessing', 'them', 'by'),\n",
       " ('rules', 'for', 'accessing', 'them', 'by', 'using'),\n",
       " ('for', 'accessing', 'them', 'by', 'using', 'module'),\n",
       " ('accessing', 'them', 'by', 'using', 'module', 'but'),\n",
       " ('them', 'by', 'using', 'module', 'but', 'nothing'),\n",
       " ('by', 'using', 'module', 'but', 'nothing', 'magical'),\n",
       " ('using', 'module', 'but', 'nothing', 'magical', 'about'),\n",
       " ('module', 'but', 'nothing', 'magical', 'about', 'these'),\n",
       " ('but', 'nothing', 'magical', 'about', 'these', 'plain'),\n",
       " ('nothing', 'magical', 'about', 'these', 'plain', 'text'),\n",
       " ('magical', 'about', 'these', 'plain', 'text', 'most'),\n",
       " ('about', 'these', 'plain', 'text', 'most', 'some'),\n",
       " ('these', 'plain', 'text', 'most', 'some', 'xml'),\n",
       " ('plain', 'text', 'most', 'some', 'xml', 'and'),\n",
       " ('text', 'most', 'some', 'xml', 'and', 'other'),\n",
       " ('most', 'some', 'xml', 'and', 'other', 'formats'),\n",
       " ('some', 'xml', 'and', 'other', 'formats', 'they'),\n",
       " ('xml', 'and', 'other', 'formats', 'they', 'accessible'),\n",
       " ('and', 'other', 'formats', 'they', 'accessible', 'you'),\n",
       " ('other', 'formats', 'they', 'accessible', 'you', 'manually'),\n",
       " ('formats', 'they', 'accessible', 'you', 'manually', 'or'),\n",
       " ('they', 'accessible', 'you', 'manually', 'or', 'via'),\n",
       " ('accessible', 'you', 'manually', 'or', 'via', 'python'),\n",
       " ('you', 'manually', 'or', 'via', 'python', 'lets'),\n",
       " ('manually', 'or', 'via', 'python', 'lets', 'talk'),\n",
       " ('or', 'via', 'python', 'lets', 'talk', 'viewing'),\n",
       " ('via', 'python', 'lets', 'talk', 'viewing', 'depending'),\n",
       " ('python', 'lets', 'talk', 'viewing', 'depending', 'on'),\n",
       " ('lets', 'talk', 'viewing', 'depending', 'on', 'your'),\n",
       " ('talk', 'viewing', 'depending', 'on', 'your', 'installation'),\n",
       " ('viewing', 'depending', 'on', 'your', 'installation', 'nltk_data'),\n",
       " ('depending', 'on', 'your', 'installation', 'nltk_data', 'directory'),\n",
       " ('on', 'your', 'installation', 'nltk_data', 'directory', 'might'),\n",
       " ('your', 'installation', 'nltk_data', 'directory', 'might', 'be'),\n",
       " ('installation', 'nltk_data', 'directory', 'might', 'be', 'hiding'),\n",
       " ('nltk_data', 'directory', 'might', 'be', 'hiding', 'multitude'),\n",
       " ('directory', 'might', 'be', 'hiding', 'multitude', 'locations'),\n",
       " ('might', 'be', 'hiding', 'multitude', 'locations', 'figure'),\n",
       " ('be', 'hiding', 'multitude', 'locations', 'figure', 'out'),\n",
       " ('hiding', 'multitude', 'locations', 'figure', 'out', 'where'),\n",
       " ('multitude', 'locations', 'figure', 'out', 'where', 'it'),\n",
       " ('locations', 'figure', 'out', 'where', 'it', 'head'),\n",
       " ('figure', 'out', 'where', 'it', 'head', 'if'),\n",
       " ('out', 'where', 'it', 'head', 'if', 'do'),\n",
       " ('where', 'it', 'head', 'if', 'do', 'not'),\n",
       " ('it', 'head', 'if', 'do', 'not', 'know'),\n",
       " ('head', 'if', 'do', 'not', 'know', 'use'),\n",
       " ('if', 'do', 'not', 'know', 'use', 'following'),\n",
       " ('do', 'not', 'know', 'use', 'following', 'code'),\n",
       " ('not', 'know', 'use', 'following', 'code', ':'),\n",
       " ('know', 'use', 'following', 'code', ':', 'run'),\n",
       " ('use', 'following', 'code', ':', 'run', 'output'),\n",
       " ('following', 'code', ':', 'run', 'output', 'will'),\n",
       " ('code', ':', 'run', 'output', 'will', 'location'),\n",
       " (':', 'run', 'output', 'will', 'location', \"'s\"),\n",
       " ('run', 'output', 'will', 'location', \"'s\", '__init__.py'),\n",
       " ('output', 'will', 'location', \"'s\", '__init__.py', 'then'),\n",
       " ('will', 'location', \"'s\", '__init__.py', 'then', 'data.py'),\n",
       " ('location', \"'s\", '__init__.py', 'then', 'data.py', 'file'),\n",
       " (\"'s\", '__init__.py', 'then', 'data.py', 'file', 'important'),\n",
       " ('__init__.py', 'then', 'data.py', 'file', 'important', 'blurb'),\n",
       " ('then', 'data.py', 'file', 'important', 'blurb', 'there'),\n",
       " ('data.py', 'file', 'important', 'blurb', 'there', 'can'),\n",
       " ('file', 'important', 'blurb', 'there', 'can', 'see'),\n",
       " ('important', 'blurb', 'there', 'can', 'see', 'various'),\n",
       " ('blurb', 'there', 'can', 'see', 'various', 'possible'),\n",
       " ('there', 'can', 'see', 'various', 'possible', 'directories'),\n",
       " ('can', 'see', 'various', 'possible', 'directories', \"'re\"),\n",
       " ('see', 'various', 'possible', 'directories', \"'re\", 'windows'),\n",
       " ('various', 'possible', 'directories', \"'re\", 'windows', 'chances'),\n",
       " ('possible', 'directories', \"'re\", 'windows', 'chances', 'appdata'),\n",
       " ('directories', \"'re\", 'windows', 'chances', 'appdata', 'local'),\n",
       " (\"'re\", 'windows', 'chances', 'appdata', 'local', 'get'),\n",
       " ('windows', 'chances', 'appdata', 'local', 'get', 'open'),\n",
       " ('chances', 'appdata', 'local', 'get', 'open', 'browser'),\n",
       " ('appdata', 'local', 'get', 'open', 'browser', 'go'),\n",
       " ('local', 'get', 'open', 'browser', 'go', 'top'),\n",
       " ('get', 'open', 'browser', 'go', 'top', 'type'),\n",
       " ('open', 'browser', 'go', 'top', 'type', '%'),\n",
       " ('browser', 'go', 'top', 'type', '%', 'next'),\n",
       " ('go', 'top', 'type', '%', 'next', 'click'),\n",
       " ('top', 'type', '%', 'next', 'click', 'roaming'),\n",
       " ('type', '%', 'next', 'click', 'roaming', 'find'),\n",
       " ('%', 'next', 'click', 'roaming', 'find', 'have'),\n",
       " ('next', 'click', 'roaming', 'find', 'have', 'full'),\n",
       " ('click', 'roaming', 'find', 'have', 'full', 'path'),\n",
       " ('roaming', 'find', 'have', 'full', 'path', 'something'),\n",
       " ('find', 'have', 'full', 'path', 'something', 'like'),\n",
       " ('have', 'full', 'path', 'something', 'like', 'within'),\n",
       " ('full', 'path', 'something', 'like', 'within', 'here'),\n",
       " ('path', 'something', 'like', 'within', 'here', 'available'),\n",
       " ('something', 'like', 'within', 'here', 'available', 'including'),\n",
       " ('like', 'within', 'here', 'available', 'including', 'things'),\n",
       " ('within', 'here', 'available', 'including', 'things', 'books'),\n",
       " ('here', 'available', 'including', 'things', 'books', 'chat'),\n",
       " ('available', 'including', 'things', 'books', 'chat', 'logs'),\n",
       " ('including', 'things', 'books', 'chat', 'logs', 'movie'),\n",
       " ('things', 'books', 'chat', 'logs', 'movie', 'reviews'),\n",
       " ('books', 'chat', 'logs', 'movie', 'reviews', 'whole'),\n",
       " ('chat', 'logs', 'movie', 'reviews', 'whole', 'lot'),\n",
       " ('logs', 'movie', 'reviews', 'whole', 'lot', 'more'),\n",
       " ('movie', 'reviews', 'whole', 'lot', 'more', 'now'),\n",
       " ('reviews', 'whole', 'lot', 'more', 'now', 'going'),\n",
       " ('whole', 'lot', 'more', 'now', 'going', 'documents'),\n",
       " ('lot', 'more', 'now', 'going', 'documents', 'as'),\n",
       " ('more', 'now', 'going', 'documents', 'as', 'mostly'),\n",
       " ('now', 'going', 'documents', 'as', 'mostly', 'so'),\n",
       " ('going', 'documents', 'as', 'mostly', 'so', 'could'),\n",
       " ('documents', 'as', 'mostly', 'so', 'could', 'just'),\n",
       " ('as', 'mostly', 'so', 'could', 'just', 'normal'),\n",
       " ('mostly', 'so', 'could', 'just', 'normal', 'read'),\n",
       " ('so', 'could', 'just', 'normal', 'read', 'said'),\n",
       " ('could', 'just', 'normal', 'read', 'said', 'has'),\n",
       " ('just', 'normal', 'read', 'said', 'has', 'few'),\n",
       " ('normal', 'read', 'said', 'has', 'few', 'nice'),\n",
       " ('read', 'said', 'has', 'few', 'nice', 'methods'),\n",
       " ('said', 'has', 'few', 'nice', 'methods', 'handling'),\n",
       " ('has', 'few', 'nice', 'methods', 'handling', 'may'),\n",
       " ('few', 'nice', 'methods', 'handling', 'may', 'useful'),\n",
       " ('nice', 'methods', 'handling', 'may', 'useful', 'their'),\n",
       " ('methods', 'handling', 'may', 'useful', 'their', 'methology'),\n",
       " ('handling', 'may', 'useful', 'their', 'methology', 'heres'),\n",
       " ('may', 'useful', 'their', 'methology', 'heres', 'an'),\n",
       " ('useful', 'their', 'methology', 'heres', 'an', 'example'),\n",
       " ('their', 'methology', 'heres', 'an', 'example', 'opening'),\n",
       " ('methology', 'heres', 'an', 'example', 'opening', 'gutenberg'),\n",
       " ('heres', 'an', 'example', 'opening', 'gutenberg', 'bible'),\n",
       " ('an', 'example', 'opening', 'gutenberg', 'bible', 'reading'),\n",
       " ('example', 'opening', 'gutenberg', 'bible', 'reading', 'first'),\n",
       " ('opening', 'gutenberg', 'bible', 'reading', 'first', 'lines')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams=list(nltk.ngrams(fdist,6))\n",
    "ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stemming : Normalize words into a based words in root \n",
    "example : affect, affecting, affected\n",
    "root : affect\n",
    "\n",
    "porterstemmer\n",
    "\n",
    "\"\"\"\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()\n",
    "pst.stem('having')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affecting : affect\n",
      "affected : affect\n",
      "going : go\n",
      "giving : give\n",
      "thinking : think\n",
      "doubted : doubt\n"
     ]
    }
   ],
   "source": [
    "stemword=['affecting', 'affected','going','giving','thinking','doubted']\n",
    "for word in stemword:\n",
    "    print(word,':' ,pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  giv\n",
      "giving :  giv\n",
      "given :  giv\n",
      "gave :  gav\n"
     ]
    }
   ],
   "source": [
    "stemword1=['give','giving','given','gave']\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst=LancasterStemmer()\n",
    "for words in stemword1:\n",
    "    print(words,\": \",lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  give\n",
      "giving :  give\n",
      "given :  given\n",
      "gave :  gave\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snbs=SnowballStemmer('english')\n",
    "for words in stemword1:\n",
    "    print(words,\": \",snbs.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  give\n",
      "giving :  giving\n",
      "given :  given\n",
      "gave :  gave\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   \n",
    "    1. Groups together different inflected forms of a word, called lemma\n",
    "    2. Some how similar to Stemming, Map several words in to one common root\n",
    "    3. OutPut Lemmatization is a Proper words\n",
    "    4. Example : a Lemmatiser should map gone, going and went into go.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordLemm=WordNetLemmatizer()\n",
    "\n",
    "wordLemm.lemmatize('corpora')\n",
    "for word in stemword1:\n",
    "    print(word,\": \",wordLemm.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords # filter a words before or after processing \n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 30),\n",
       " ('the', 28),\n",
       " ('.', 16),\n",
       " ('to', 10),\n",
       " ('you', 10),\n",
       " ('of', 9),\n",
       " ('and', 9),\n",
       " ('nltk', 8),\n",
       " ('is', 8),\n",
       " ('in', 7)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))\n",
    "fdist10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'this',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tutorial',\n",
       " 'I',\n",
       " 'want',\n",
       " 'us',\n",
       " 'to',\n",
       " 'take',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'to',\n",
       " 'peak',\n",
       " 'into',\n",
       " 'the',\n",
       " 'corpora',\n",
       " 'we',\n",
       " 'all',\n",
       " 'downloaded',\n",
       " 'The',\n",
       " 'NLTK',\n",
       " 'corpus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'massive',\n",
       " 'dump',\n",
       " 'of',\n",
       " 'all',\n",
       " 'kinds',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'that',\n",
       " 'are',\n",
       " 'definitely',\n",
       " 'worth',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'look',\n",
       " 'at',\n",
       " 'Almost',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'files',\n",
       " 'in',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'corpus',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'same',\n",
       " 'rules',\n",
       " 'for',\n",
       " 'accessing',\n",
       " 'them',\n",
       " 'by',\n",
       " 'using',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'module',\n",
       " 'but',\n",
       " 'nothing',\n",
       " 'is',\n",
       " 'magical',\n",
       " 'about',\n",
       " 'them',\n",
       " 'These',\n",
       " 'files',\n",
       " 'are',\n",
       " 'plain',\n",
       " 'text',\n",
       " 'files',\n",
       " 'for',\n",
       " 'the',\n",
       " 'most',\n",
       " 'part',\n",
       " 'some',\n",
       " 'are',\n",
       " 'XML',\n",
       " 'and',\n",
       " 'some',\n",
       " 'are',\n",
       " 'other',\n",
       " 'formats',\n",
       " 'but',\n",
       " 'they',\n",
       " 'are',\n",
       " 'all',\n",
       " 'accessible',\n",
       " 'by',\n",
       " 'you',\n",
       " 'manually',\n",
       " 'or',\n",
       " 'via',\n",
       " 'the',\n",
       " 'module',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'Lets',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'viewing',\n",
       " 'them',\n",
       " 'manually',\n",
       " 'Depending',\n",
       " 'on',\n",
       " 'your',\n",
       " 'installation',\n",
       " 'your',\n",
       " 'nltkdata',\n",
       " 'directory',\n",
       " 'might',\n",
       " 'be',\n",
       " 'hiding',\n",
       " 'in',\n",
       " 'a',\n",
       " 'multitude',\n",
       " 'of',\n",
       " 'locations',\n",
       " 'To',\n",
       " 'figure',\n",
       " 'out',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'head',\n",
       " 'to',\n",
       " 'your',\n",
       " 'Python',\n",
       " 'directory',\n",
       " 'where',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'module',\n",
       " 'is',\n",
       " 'If',\n",
       " 'you',\n",
       " 'do',\n",
       " 'not',\n",
       " 'know',\n",
       " 'where',\n",
       " 'that',\n",
       " 'is',\n",
       " 'use',\n",
       " 'the',\n",
       " 'following',\n",
       " 'code',\n",
       " 'Run',\n",
       " 'that',\n",
       " 'and',\n",
       " 'the',\n",
       " 'output',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'location',\n",
       " 'of',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'module',\n",
       " \"'s\",\n",
       " 'initpy',\n",
       " 'Head',\n",
       " 'into',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'directory',\n",
       " 'and',\n",
       " 'then',\n",
       " 'look',\n",
       " 'for',\n",
       " 'the',\n",
       " 'datapy',\n",
       " 'file',\n",
       " 'The',\n",
       " 'important',\n",
       " 'blurb',\n",
       " 'of',\n",
       " 'code',\n",
       " 'is',\n",
       " 'There',\n",
       " 'you',\n",
       " 'can',\n",
       " 'see',\n",
       " 'the',\n",
       " 'various',\n",
       " 'possible',\n",
       " 'directories',\n",
       " 'for',\n",
       " 'the',\n",
       " 'nltkdata',\n",
       " 'If',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'on',\n",
       " 'Windows',\n",
       " 'chances',\n",
       " 'are',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'your',\n",
       " 'appdata',\n",
       " 'in',\n",
       " 'the',\n",
       " 'local',\n",
       " 'directory',\n",
       " 'To',\n",
       " 'get',\n",
       " 'there',\n",
       " 'you',\n",
       " 'will',\n",
       " 'want',\n",
       " 'to',\n",
       " 'open',\n",
       " 'your',\n",
       " 'file',\n",
       " 'browser',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'top',\n",
       " 'and',\n",
       " 'type',\n",
       " 'in',\n",
       " '%',\n",
       " 'appdata',\n",
       " '%',\n",
       " 'Next',\n",
       " 'click',\n",
       " 'on',\n",
       " 'roaming',\n",
       " 'and',\n",
       " 'then',\n",
       " 'find',\n",
       " 'the',\n",
       " 'nltkdata',\n",
       " 'directory',\n",
       " 'In',\n",
       " 'there',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'your',\n",
       " 'corpora',\n",
       " 'file',\n",
       " 'The',\n",
       " 'full',\n",
       " 'path',\n",
       " 'is',\n",
       " 'something',\n",
       " 'like',\n",
       " 'Within',\n",
       " 'here',\n",
       " 'you',\n",
       " 'have',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'available',\n",
       " 'corpora',\n",
       " 'including',\n",
       " 'things',\n",
       " 'like',\n",
       " 'books',\n",
       " 'chat',\n",
       " 'logs',\n",
       " 'movie',\n",
       " 'reviews',\n",
       " 'and',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'Now',\n",
       " 'we',\n",
       " \"'re\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'accessing',\n",
       " 'these',\n",
       " 'documents',\n",
       " 'via',\n",
       " 'NLTK',\n",
       " 'As',\n",
       " 'you',\n",
       " 'can',\n",
       " 'see',\n",
       " 'these',\n",
       " 'are',\n",
       " 'mostly',\n",
       " 'text',\n",
       " 'documents',\n",
       " 'so',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'use',\n",
       " 'normal',\n",
       " 'Python',\n",
       " 'code',\n",
       " 'to',\n",
       " 'open',\n",
       " 'and',\n",
       " 'read',\n",
       " 'documents',\n",
       " 'That',\n",
       " 'said',\n",
       " 'the',\n",
       " 'NLTK',\n",
       " 'module',\n",
       " 'has',\n",
       " 'a',\n",
       " 'few',\n",
       " 'nice',\n",
       " 'methods',\n",
       " 'for',\n",
       " 'handling',\n",
       " 'the',\n",
       " 'corpus',\n",
       " 'so',\n",
       " 'you',\n",
       " 'may',\n",
       " 'find',\n",
       " 'it',\n",
       " 'useful',\n",
       " 'to',\n",
       " 'use',\n",
       " 'their',\n",
       " 'methology',\n",
       " 'Heres',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'us',\n",
       " 'opening',\n",
       " 'the',\n",
       " 'Gutenberg',\n",
       " 'Bible',\n",
       " 'and',\n",
       " 'reading',\n",
       " 'the',\n",
       " 'first',\n",
       " 'few',\n",
       " 'lines']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "punctutation=re.compile(r'[_.?!,:;()0-9]')\n",
    "postPunction=[]\n",
    "for words in tokenWord:\n",
    "    word=punctutation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        postPunction.append(word)\n",
    "postPunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN')]\n",
      "[('this', 'DT')]\n",
      "[('part', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('tutorial', 'NN')]\n",
      "[(',', ',')]\n",
      "[('I', 'PRP')]\n",
      "[('want', 'NN')]\n",
      "[('us', 'PRP')]\n",
      "[('to', 'TO')]\n",
      "[('take', 'VB')]\n",
      "[('a', 'DT')]\n",
      "[('moment', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('peak', 'NN')]\n",
      "[('into', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('corpora', 'NNS')]\n",
      "[('we', 'PRP')]\n",
      "[('all', 'DT')]\n",
      "[('downloaded', 'VBN')]\n",
      "[('!', '.')]\n",
      "[('The', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('corpus', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('massive', 'JJ')]\n",
      "[('dump', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('all', 'DT')]\n",
      "[('kinds', 'NNS')]\n",
      "[('of', 'IN')]\n",
      "[('natural', 'JJ')]\n",
      "[('language', 'NN')]\n",
      "[('data', 'NNS')]\n",
      "[('sets', 'NNS')]\n",
      "[('that', 'IN')]\n",
      "[('are', 'VBP')]\n",
      "[('definitely', 'RB')]\n",
      "[('worth', 'NN')]\n",
      "[('taking', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('look', 'NN')]\n",
      "[('at', 'IN')]\n",
      "[('.', '.')]\n",
      "[('Almost', 'RB')]\n",
      "[('all', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('files', 'NNS')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('corpus', 'NN')]\n",
      "[('follow', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('same', 'JJ')]\n",
      "[('rules', 'NNS')]\n",
      "[('for', 'IN')]\n",
      "[('accessing', 'VBG')]\n",
      "[('them', 'PRP')]\n",
      "[('by', 'IN')]\n",
      "[('using', 'VBG')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('module', 'NN')]\n",
      "[(',', ',')]\n",
      "[('but', 'CC')]\n",
      "[('nothing', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('magical', 'JJ')]\n",
      "[('about', 'IN')]\n",
      "[('them', 'PRP')]\n",
      "[('.', '.')]\n",
      "[('These', 'DT')]\n",
      "[('files', 'NNS')]\n",
      "[('are', 'VBP')]\n",
      "[('plain', 'NN')]\n",
      "[('text', 'NN')]\n",
      "[('files', 'NNS')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('most', 'JJS')]\n",
      "[('part', 'NN')]\n",
      "[(',', ',')]\n",
      "[('some', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('XML', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('some', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('other', 'JJ')]\n",
      "[('formats', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('but', 'CC')]\n",
      "[('they', 'PRP')]\n",
      "[('are', 'VBP')]\n",
      "[('all', 'DT')]\n",
      "[('accessible', 'JJ')]\n",
      "[('by', 'IN')]\n",
      "[('you', 'PRP')]\n",
      "[('manually', 'RB')]\n",
      "[(',', ',')]\n",
      "[('or', 'CC')]\n",
      "[('via', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('module', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('Python', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Lets', 'NNS')]\n",
      "[('talk', 'NN')]\n",
      "[('about', 'IN')]\n",
      "[('viewing', 'VBG')]\n",
      "[('them', 'PRP')]\n",
      "[('manually', 'RB')]\n",
      "[('.', '.')]\n",
      "[('Depending', 'VBG')]\n",
      "[('on', 'IN')]\n",
      "[('your', 'PRP$')]\n",
      "[('installation', 'NN')]\n",
      "[(',', ',')]\n",
      "[('your', 'PRP$')]\n",
      "[('nltk_data', 'NNS')]\n",
      "[('directory', 'NN')]\n",
      "[('might', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('hiding', 'NN')]\n",
      "[('in', 'IN')]\n",
      "[('a', 'DT')]\n",
      "[('multitude', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('locations', 'NNS')]\n",
      "[('.', '.')]\n",
      "[('To', 'TO')]\n",
      "[('figure', 'NN')]\n",
      "[('out', 'IN')]\n",
      "[('where', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('is', 'VBZ')]\n",
      "[(',', ',')]\n",
      "[('head', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('your', 'PRP$')]\n",
      "[('Python', 'NN')]\n",
      "[('directory', 'NN')]\n",
      "[(',', ',')]\n",
      "[('where', 'WRB')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('module', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('.', '.')]\n",
      "[('If', 'IN')]\n",
      "[('you', 'PRP')]\n",
      "[('do', 'VB')]\n",
      "[('not', 'RB')]\n",
      "[('know', 'VB')]\n",
      "[('where', 'WRB')]\n",
      "[('that', 'IN')]\n",
      "[('is', 'VBZ')]\n",
      "[(',', ',')]\n",
      "[('use', 'NN')]\n",
      "[('the', 'DT')]\n",
      "[('following', 'VBG')]\n",
      "[('code', 'NN')]\n",
      "[(':', ':')]\n",
      "[('Run', 'VB')]\n",
      "[('that', 'IN')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('the', 'DT')]\n",
      "[('output', 'NN')]\n",
      "[('will', 'MD')]\n",
      "[('be', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('location', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('module', 'NN')]\n",
      "[(\"'s\", 'POS')]\n",
      "[('__init__.py', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Head', 'NN')]\n",
      "[('into', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('directory', 'NN')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('then', 'RB')]\n",
      "[('look', 'NN')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('data.py', 'NN')]\n",
      "[('file', 'NN')]\n",
      "[('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('important', 'JJ')]\n",
      "[('blurb', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('code', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[(':', ':')]\n",
      "[('There', 'EX')]\n",
      "[(',', ',')]\n",
      "[('you', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('see', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('various', 'JJ')]\n",
      "[('possible', 'JJ')]\n",
      "[('directories', 'NNS')]\n",
      "[('for', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('nltk_data', 'NNS')]\n",
      "[('.', '.')]\n",
      "[('If', 'IN')]\n",
      "[('you', 'PRP')]\n",
      "[(\"'re\", 'VBP')]\n",
      "[('on', 'IN')]\n",
      "[('Windows', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('chances', 'NNS')]\n",
      "[('are', 'VBP')]\n",
      "[('it', 'PRP')]\n",
      "[('is', 'VBZ')]\n",
      "[('in', 'IN')]\n",
      "[('your', 'PRP$')]\n",
      "[('appdata', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('in', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('local', 'JJ')]\n",
      "[('directory', 'NN')]\n",
      "[('.', '.')]\n",
      "[('To', 'TO')]\n",
      "[('get', 'VB')]\n",
      "[('there', 'RB')]\n",
      "[(',', ',')]\n",
      "[('you', 'PRP')]\n",
      "[('will', 'MD')]\n",
      "[('want', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('open', 'JJ')]\n",
      "[('your', 'PRP$')]\n",
      "[('file', 'NN')]\n",
      "[('browser', 'NN')]\n",
      "[(',', ',')]\n",
      "[('go', 'VB')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('top', 'NN')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('type', 'NN')]\n",
      "[('in', 'IN')]\n",
      "[('%', 'NN')]\n",
      "[('appdata', 'NNS')]\n",
      "[('%', 'NN')]\n",
      "[('Next', 'JJ')]\n",
      "[('click', 'NN')]\n",
      "[('on', 'IN')]\n",
      "[('roaming', 'VBG')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('then', 'RB')]\n",
      "[('find', 'VB')]\n",
      "[('the', 'DT')]\n",
      "[('nltk_data', 'NNS')]\n",
      "[('directory', 'NN')]\n",
      "[('.', '.')]\n",
      "[('In', 'IN')]\n",
      "[('there', 'RB')]\n",
      "[(',', ',')]\n",
      "[('you', 'PRP')]\n",
      "[('will', 'MD')]\n",
      "[('have', 'VB')]\n",
      "[('your', 'PRP$')]\n",
      "[('corpora', 'NNS')]\n",
      "[('file', 'NN')]\n",
      "[('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('full', 'JJ')]\n",
      "[('path', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('something', 'NN')]\n",
      "[('like', 'IN')]\n",
      "[(':', ':')]\n",
      "[('Within', 'IN')]\n",
      "[('here', 'RB')]\n",
      "[(',', ',')]\n",
      "[('you', 'PRP')]\n",
      "[('have', 'VB')]\n",
      "[('all', 'DT')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('available', 'JJ')]\n",
      "[('corpora', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('including', 'VBG')]\n",
      "[('things', 'NNS')]\n",
      "[('like', 'IN')]\n",
      "[('books', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('chat', 'NN')]\n",
      "[('logs', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('movie', 'NN')]\n",
      "[('reviews', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('a', 'DT')]\n",
      "[('whole', 'JJ')]\n",
      "[('lot', 'NN')]\n",
      "[('more', 'RBR')]\n",
      "[('.', '.')]\n",
      "[('Now', 'RB')]\n",
      "[(',', ',')]\n",
      "[('we', 'PRP')]\n",
      "[(\"'re\", 'VBP')]\n",
      "[('going', 'VBG')]\n",
      "[('to', 'TO')]\n",
      "[('talk', 'NN')]\n",
      "[('about', 'IN')]\n",
      "[('accessing', 'VBG')]\n",
      "[('these', 'DT')]\n",
      "[('documents', 'NNS')]\n",
      "[('via', 'IN')]\n",
      "[('NLTK', 'NN')]\n",
      "[('.', '.')]\n",
      "[('As', 'IN')]\n",
      "[('you', 'PRP')]\n",
      "[('can', 'MD')]\n",
      "[('see', 'VB')]\n",
      "[(',', ',')]\n",
      "[('these', 'DT')]\n",
      "[('are', 'VBP')]\n",
      "[('mostly', 'RB')]\n",
      "[('text', 'NN')]\n",
      "[('documents', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('so', 'RB')]\n",
      "[('you', 'PRP')]\n",
      "[('could', 'MD')]\n",
      "[('just', 'RB')]\n",
      "[('use', 'NN')]\n",
      "[('normal', 'JJ')]\n",
      "[('Python', 'NN')]\n",
      "[('code', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('open', 'JJ')]\n",
      "[('and', 'CC')]\n",
      "[('read', 'NN')]\n",
      "[('documents', 'NNS')]\n",
      "[('.', '.')]\n",
      "[('That', 'DT')]\n",
      "[('said', 'VBD')]\n",
      "[(',', ',')]\n",
      "[('the', 'DT')]\n",
      "[('NLTK', 'NN')]\n",
      "[('module', 'NN')]\n",
      "[('has', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('few', 'JJ')]\n",
      "[('nice', 'JJ')]\n",
      "[('methods', 'NNS')]\n",
      "[('for', 'IN')]\n",
      "[('handling', 'VBG')]\n",
      "[('the', 'DT')]\n",
      "[('corpus', 'NN')]\n",
      "[(',', ',')]\n",
      "[('so', 'RB')]\n",
      "[('you', 'PRP')]\n",
      "[('may', 'MD')]\n",
      "[('find', 'VB')]\n",
      "[('it', 'PRP')]\n",
      "[('useful', 'JJ')]\n",
      "[('to', 'TO')]\n",
      "[('use', 'NN')]\n",
      "[('their', 'PRP$')]\n",
      "[('methology', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Heres', 'NNS')]\n",
      "[('an', 'DT')]\n",
      "[('example', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('us', 'PRP')]\n",
      "[('opening', 'NN')]\n",
      "[('the', 'DT')]\n",
      "[('Gutenberg', 'NNP')]\n",
      "[('Bible', 'JJ')]\n",
      "[(',', ',')]\n",
      "[('and', 'CC')]\n",
      "[('reading', 'NN')]\n",
      "[('the', 'DT')]\n",
      "[('first', 'RB')]\n",
      "[('few', 'JJ')]\n",
      "[('lines', 'NNS')]\n",
      "[(':', ':')]\n"
     ]
    }
   ],
   "source": [
    "\"POS : Part of speech \"\n",
    "for word in tokenWord:\n",
    "    print(nltk.pos_tag([word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stay/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY White/NNP House/NNP))\n"
     ]
    }
   ],
   "source": [
    "\"NER: Name Entity Recognition is a None phase recognition like Movie, Location, Monetary Value, Organization, Quantity and Person\"\n",
    "from nltk import ne_chunk\n",
    "sentence='The US President stay in the White House '\n",
    "val=word_tokenize(sentence)\n",
    "postag=nltk.pos_tag(val)\n",
    "ner=ne_chunk(postag)\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             subprocess.call([find_binary('gs', binary_names=['gswin32c.exe', 'gswin64c.exe'], env_vars=['PATH'], verbose=False)] +\n\u001b[0m\u001b[0;32m    731\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                             .format(out_path, in_path).split())\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 binary_names=None, url=None, verbose=False):\n\u001b[0;32m    603\u001b[0m     return next(find_binary_iter(name, path_to_bin, env_vars, searchpath,\n\u001b[1;32m--> 604\u001b[1;33m                                  binary_names, url, verbose))\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m def find_jar_iter(name_pattern, path_to_jar=None, env_vars=(),\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m    597\u001b[0m     for file in  find_file_iter(path_to_bin or name, env_vars, searchpath, binary_names,\n\u001b[1;32m--> 598\u001b[1;33m                      url, verbose):\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    567\u001b[0m                         (filename, url))\n\u001b[0;32m    568\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('The', 'DT'), ('Cat', 'NNP'), ('sat', 'VBD'), ('under', 'IN'), ('the', 'DT'), ('Mat', 'NNP')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"Syntax tree : ghostscript download\"\n",
    "\n",
    "new=\"The Cat sat under the Mat\"\n",
    "#\"Chuncking is grouping all words \"\n",
    "val=nltk.pos_tag(word_tokenize(new))\n",
    "grammer=r'NP:{<DT>?<JJ>*<NN>}'\n",
    "chunk=nltk.RegexpParser(grammer)\n",
    "chunkResult=chunk.parse(val)\n",
    "chunkResult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
